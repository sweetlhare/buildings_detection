{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce4eede6-532a-428d-b4eb-eee7bb007c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from sahi.prediction import ObjectPrediction, PredictionResult\n",
    "from sahi.annotation import BoundingBox, Mask, Category\n",
    "from sahi.slicing import slice_image\n",
    "from sahi.postprocess.combine import GreedyNMMPostprocess\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_prediction, get_sliced_prediction\n",
    "\n",
    "\n",
    "def process_tif(path_to_tif):\n",
    "    return np.array(Image.open(path_to_tif))\n",
    "    \n",
    "\n",
    "# def pix_to_geo(path_to_tif, pix_polygons):\n",
    "        \n",
    "#         with rasterio.open(path_to_tif) as image:\n",
    "            \n",
    "#             geo_coords_all = []\n",
    "            \n",
    "#             for pix_polygon in pix_polygons:\n",
    "            \n",
    "#                 array_with_geo_coords = []\n",
    "#                 for pix in pix_polygon:\n",
    "#                     geo_xy = image.xy(pix[1], pix[0])\n",
    "#                     array_with_geo_coords.append([geo_xy[0], geo_xy[1]])\n",
    "                \n",
    "#                 geo_coords_all.append(array_with_geo_coords)\n",
    "                \n",
    "#         return geo_coords_all\n",
    "\n",
    "\n",
    "def get_shifted_mask(bool_mask, \n",
    "                     full_shape_width, full_shape_height,\n",
    "                     shift_x, shift_y\n",
    "                    ):\n",
    "    \n",
    "    mask_fullsized = np.full(\n",
    "        (\n",
    "            full_shape_height,\n",
    "            full_shape_width,\n",
    "        ),\n",
    "        0,\n",
    "        dtype=\"uint8\",\n",
    "    )\n",
    "    # arrange starting ending indexes\n",
    "    starting_pixel = [shift_x, shift_y]\n",
    "    ending_pixel = [\n",
    "        min(starting_pixel[0] + bool_mask.shape[1], full_shape_width),\n",
    "        min(starting_pixel[1] + bool_mask.shape[0], full_shape_height),\n",
    "    ]\n",
    "    # convert sliced mask to full mask\n",
    "    mask_fullsized[starting_pixel[1] : ending_pixel[1], starting_pixel[0] : ending_pixel[0]] = bool_mask[\n",
    "        : ending_pixel[1] - starting_pixel[1], : ending_pixel[0] - starting_pixel[0]\n",
    "    ]\n",
    "\n",
    "    return mask_fullsized\n",
    "\n",
    "\n",
    "def get_coco_segmentation_from_bool_mask(bool_mask):\n",
    "    \"\"\"\n",
    "    Convert boolean mask to coco segmentation format\n",
    "    [\n",
    "        [x1, y1, x2, y2, x3, y3, ...],\n",
    "        [x1, y1, x2, y2, x3, y3, ...],\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    # Generate polygons from mask\n",
    "    mask = np.squeeze(bool_mask)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask = cv2.copyMakeBorder(mask, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0)\n",
    "    polygons = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE, offset=(-1, -1))\n",
    "    polygons = polygons[0] if len(polygons) == 2 else polygons[1]\n",
    "    # Convert polygon to coco segmentation\n",
    "    coco_segmentation = []\n",
    "    for polygon in polygons:\n",
    "        segmentation = polygon.flatten().tolist()\n",
    "        # at least 3 points needed for a polygon\n",
    "        if len(segmentation) >= 6:\n",
    "            coco_segmentation.append(segmentation)\n",
    "    return coco_segmentation\n",
    "\n",
    "\n",
    "def draw_polygon(image, points, color=(0, 255, 0), alpha=0.5):\n",
    "    # Создаем копию изображения\n",
    "    img_copy = np.copy(image)\n",
    "    \n",
    "    # Создаем маску для заполнения полигона цветом\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    for pts in points:\n",
    "        pts = np.array(points, np.int32)\n",
    "        # Заполняем полигон цветом на маске\n",
    "        cv2.fillPoly(mask, [pts], color)\n",
    "    \n",
    "    # Объединяем изображение с маской с учетом альфа-канала\n",
    "    img_copy = cv2.addWeighted(mask, alpha, img_copy, 1 - alpha, 0)\n",
    "    \n",
    "    return img_copy\n",
    "    \n",
    "\n",
    "def process_building_image(image_path):\n",
    "\n",
    "    print('load')\n",
    "    \n",
    "    img = process_tif(image_path)\n",
    "    # img = np.copy(np.concatenate([img[..., 2:3], img[..., 1:2], img[..., 0:1]], axis=2))\n",
    "\n",
    "    print('load done')\n",
    "\n",
    "    model = YOLO('best_from_server.pt')\n",
    "    # model = YOLO('best_ours.pt')\n",
    "\n",
    "    imgsz = 512\n",
    "    \n",
    "    sliced_list = []\n",
    "\n",
    "    sliced = slice_image(\n",
    "        image=img,\n",
    "        slice_height=imgsz,\n",
    "        slice_width=imgsz,\n",
    "        overlap_height_ratio=0.6,\n",
    "        overlap_width_ratio=0.6,\n",
    "    )\n",
    "\n",
    "    full_shape_width = sliced.original_image_width\n",
    "    full_shape_height = sliced.original_image_height\n",
    "    \n",
    "    result_mask = np.uint8(np.zeros((full_shape_height, full_shape_width)))\n",
    "    \n",
    "    for i in tqdm(range(len(sliced.filenames))):\n",
    "        \n",
    "        pred = model.predict(sliced.images[i][..., :3], max_det=1000, save=False, conf=0.3, device=0, verbose=False)[0]\n",
    "        filename = sliced.filenames[i]\n",
    "        \n",
    "        shift_x = int(filename.split('_')[1])\n",
    "        shift_y = int(filename.split('_')[2])\n",
    "        shape_width = int(filename.split('_')[3]) - int(filename.split('_')[1])\n",
    "        shape_height = int(filename.split('_')[4].split('.')[0]) - int(filename.split('_')[2])\n",
    "        \n",
    "        if pred.masks != None:\n",
    "        \n",
    "            masks = []\n",
    "            for mask in pred.masks.data.cpu().numpy():\n",
    "                mask = np.uint8(cv2.resize(mask, (shape_width, shape_height)))\n",
    "                masks.append(mask)\n",
    "    \n",
    "            for mask in masks:\n",
    "\n",
    "                # if mask.sum() / (shape_width * shape_height) > 0.01:\n",
    "                mask_ = get_shifted_mask(mask, full_shape_width, full_shape_height, shift_x, shift_y)\n",
    "                result_mask += mask_\n",
    "                \n",
    "    result_mask = np.clip(result_mask, 0, 1)\n",
    "    coco_segmentation = get_coco_segmentation_from_bool_mask(result_mask)\n",
    "\n",
    "\n",
    "    pix_coords_all = []\n",
    "    for pix_coords in tqdm(coco_segmentation):\n",
    "        # pix_coords = pix_coords.to_coco_annotation().segmentation[0]\n",
    "        pix_coords = [[pix_coords[i], pix_coords[i+1]] for i in range(0, len(pix_coords), 2)]\n",
    "        pix_coords = np.asarray(pix_coords)\n",
    "        # epsilon = 1.5\n",
    "        # pix_coords = np.array(rdp(pix_coords, epsilon))\n",
    "        pix_coords_all.append(pix_coords)\n",
    "\n",
    "    # geo_coords = pix_to_geo(image_path, pix_coords_all)\n",
    "\n",
    "\n",
    "    # with rasterio.open(image_path) as src:\n",
    "\n",
    "    #     geo_coords_all = []    \n",
    "        \n",
    "    #     for pix_polygon in pix_coords_all:\n",
    "    #         array_with_geo_coords = []\n",
    "    #         for pix in pix_polygon:\n",
    "    #             geo_xy = src.xy(pix[1], pix[0])\n",
    "    #             array_with_geo_coords.append([geo_xy[0], geo_xy[1]])\n",
    "                \n",
    "    #         geo_coords_all.append(array_with_geo_coords)\n",
    "\n",
    "    #     transformer = Transformer.from_crs(src.crs.data['init'], \"EPSG:4326\")\n",
    "\n",
    "    #     for i in range(len(geo_coords)):\n",
    "    #         for j in range(len(geo_coords[i])):\n",
    "    #             xy_ = transformer.transform(geo_coords[i][j][0], geo_coords[i][j][1])\n",
    "    #             geo_coords[i][j] = [xy_[1], xy_[0]]\n",
    "\n",
    "\n",
    "    # polygon_gdf =  gpd.GeoDataFrame(geometry=[Polygon([(x, y) for x, y  in geo_c]) for geo_c in geo_coords if len(geo_c) >= 3])\n",
    "\n",
    "    color=(0, 0, 255)\n",
    "    alpha=0.2\n",
    "    thickness=2\n",
    "    img = np.array(img).copy()\n",
    "    \n",
    "    points = []\n",
    "    for pts in coco_segmentation:\n",
    "        pts_ = []\n",
    "        for i in range(0, len(pts), 2):\n",
    "            pts_.append([pts[i], pts[i+1]])\n",
    "        points.append(pts_)\n",
    "        \n",
    "    # Создаем копию изображения\n",
    "    # img_copy = np.copy(np.concatenate([img[..., 2:3], img[..., 1:2], img[..., 0:1]], axis=2))\n",
    "    img_copy = img.copy()\n",
    "    # Создаем маску для заполнения полигона цветом\n",
    "    mask = np.zeros_like(img)\n",
    "    for pts in points:\n",
    "        pts = np.array(pts, np.int32)\n",
    "        cv2.polylines(img_copy, [pts], True, color, thickness)\n",
    "        cv2.fillPoly(mask, [pts], color)\n",
    "    # Объединяем изображение с маской с учетом альфа-канала\n",
    "    # img_copy = cv2.addWeighted(mask, alpha, img_copy, 1 - alpha, 0)\n",
    "\n",
    "    filename = image_path.split('/')[-1]\n",
    "    Image.fromarray(np.uint8(mask)).save(f'sub1/{filename}'.replace('image', 'VIEWmask'))\n",
    "    Image.fromarray(np.uint8(img_copy)).save(f'sub1/{filename}')\n",
    "\n",
    "\n",
    "    color=(0, 0, 1)\n",
    "    alpha=0.2\n",
    "    thickness=2\n",
    "    img = np.array(img).copy()\n",
    "    \n",
    "    points = []\n",
    "    for pts in coco_segmentation:\n",
    "        pts_ = []\n",
    "        for i in range(0, len(pts), 2):\n",
    "            pts_.append([pts[i], pts[i+1]])\n",
    "        points.append(pts_)\n",
    "        \n",
    "    # Создаем копию изображения\n",
    "    # img_copy = np.copy(np.concatenate([img[..., 2:3], img[..., 1:2], img[..., 0:1]], axis=2))\n",
    "    img_copy = img.copy()\n",
    "    # Создаем маску для заполнения полигона цветом\n",
    "    mask = np.zeros_like(img)\n",
    "    for pts in points:\n",
    "        pts = np.array(pts, np.int32)\n",
    "        cv2.polylines(img_copy, [pts], True, color, thickness)\n",
    "        cv2.fillPoly(mask, [pts], color)\n",
    "    # Объединяем изображение с маской с учетом альфа-канала\n",
    "    # img_copy = cv2.addWeighted(mask, alpha, img_copy, 1 - alpha, 0)\n",
    "\n",
    "    filename = image_path.split('/')[-1]\n",
    "    Image.fromarray(np.uint8(mask)).save(f'sub1/{filename}'.replace('image', 'mask'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26d8ee06-d2fa-4bcc-a391-52074cfb800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "load done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▉                                                      | 571/1813 [01:47<03:54,  5.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_dataset_test/images/test_image_000.png\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#           'test_dataset_test/images/test_image_001.png',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m               \u001b[38;5;66;03m# 'test_dataset_test/images/test_image_007.png'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m ]:\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mprocess_building_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[105], line 159\u001b[0m, in \u001b[0;36mprocess_building_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m    154\u001b[0m             masks\u001b[38;5;241m.\u001b[39mappend(mask)\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m masks:\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m             \u001b[38;5;66;03m# if mask.sum() / (shape_width * shape_height) > 0.01:\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m             mask_ \u001b[38;5;241m=\u001b[39m \u001b[43mget_shifted_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_shape_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_shape_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m             result_mask \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mask_\n\u001b[0;32m    162\u001b[0m result_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(result_mask, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[105], line 45\u001b[0m, in \u001b[0;36mget_shifted_mask\u001b[1;34m(bool_mask, full_shape_width, full_shape_height, shift_x, shift_y)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_shifted_mask\u001b[39m(bool_mask, \n\u001b[0;32m     41\u001b[0m                      full_shape_width, full_shape_height,\n\u001b[0;32m     42\u001b[0m                      shift_x, shift_y\n\u001b[0;32m     43\u001b[0m                     ):\n\u001b[1;32m---> 45\u001b[0m     mask_fullsized \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfull_shape_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfull_shape_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# arrange starting ending indexes\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     starting_pixel \u001b[38;5;241m=\u001b[39m [shift_x, shift_y]\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\cv\\lib\\site-packages\\numpy\\core\\numeric.py:345\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    343\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    344\u001b[0m a \u001b[38;5;241m=\u001b[39m empty(shape, dtype, order)\n\u001b[1;32m--> 345\u001b[0m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcopyto\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for image in [\n",
    "    'test_dataset_test/images/test_image_000.png',\n",
    "    #           'test_dataset_test/images/test_image_001.png',\n",
    "    #           'test_dataset_test/images/test_image_002.png',\n",
    "    #           'test_dataset_test/images/test_image_003.png',\n",
    "              # 'test_dataset_test/images/test_image_004.png',\n",
    "              # 'test_dataset_test/images/test_image_005.png',\n",
    "              # 'test_dataset_test/images/test_image_006.png',\n",
    "              # 'test_dataset_test/images/test_image_007.png'\n",
    "]:\n",
    "\n",
    "    process_building_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d8b22-c694-4f18-a21d-7a408f8ab950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91c42fc3-c227-4637-b59c-04169036b36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cv2.imread('sub1/test_image_000.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90832199-3763-4c8e-a99e-89104aed58fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041bfe3-2e44-4bbc-8bae-968bc3771b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3091cf3a-5c5f-49e6-857d-eb1233b19fc2",
   "metadata": {},
   "source": [
    "# mask to yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d10859-9708-4bc4-a60e-cb75893a27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coco_segmentation_from_bool_mask(bool_mask):\n",
    "    \"\"\"\n",
    "    Convert boolean mask to coco segmentation format\n",
    "    [\n",
    "        [x1, y1, x2, y2, x3, y3, ...],\n",
    "        [x1, y1, x2, y2, x3, y3, ...],\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    # Generate polygons from mask\n",
    "    mask = np.squeeze(bool_mask)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask = cv2.copyMakeBorder(mask, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0)\n",
    "    polygons = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE, offset=(-1, -1))\n",
    "    polygons = polygons[0] if len(polygons) == 2 else polygons[1]\n",
    "    # Convert polygon to coco segmentation\n",
    "    coco_segmentation = []\n",
    "    for polygon in polygons:\n",
    "        segmentation = polygon.flatten().tolist()\n",
    "        # at least 3 points needed for a polygon\n",
    "        if len(segmentation) >= 6:\n",
    "            coco_segmentation.append(segmentation)\n",
    "    return coco_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3602d4e-1595-4195-815f-253aa202f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data/train/labels', exist_ok=True)\n",
    "os.makedirs('data/test/labels', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac7cca25-61a6-46a1-abb6-dee7b6d013f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask_path in glob('data/train/mask/*'):\n",
    "    \n",
    "    filename = mask_path.split('/')[-1].split('\\\\')[-1].split('.')[0]\n",
    "    mask = np.array(Image.open(f'data/train/mask/{filename}.png'))\n",
    "    \n",
    "    coco_seg = get_coco_segmentation_from_bool_mask(mask[..., 0])\n",
    "\n",
    "    yolo_s = []\n",
    "    for seg in coco_seg:\n",
    "        yolo_s.append('0 '+' '.join([str(x / 512) for x in seg]))\n",
    "    yolo_s = '\\n'.join(yolo_s)\n",
    "    \n",
    "    with open(f'data/train/labels/{filename}.txt', 'w') as f:\n",
    "        f.write(yolo_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15c176a9-31dc-4684-883c-fbe0536e252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask_path in glob('data/test/mask/*'):\n",
    "    \n",
    "    filename = mask_path.split('/')[-1].split('\\\\')[-1].split('.')[0]\n",
    "    mask = np.array(Image.open(f'data/test/mask/{filename}.png'))\n",
    "    \n",
    "    coco_seg = get_coco_segmentation_from_bool_mask(mask[..., 0])\n",
    "\n",
    "    yolo_s = []\n",
    "    for seg in coco_seg:\n",
    "        yolo_s.append('0 '+' '.join([str(x / 512) for x in seg]))\n",
    "    yolo_s = '\\n'.join(yolo_s)\n",
    "    \n",
    "    with open(f'data/test/labels/{filename}.txt', 'w') as f:\n",
    "        f.write(yolo_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5208ec-5aea-4e86-9c6e-817df46ee56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ee582d5-9b0a-43d3-af8d-fe9e8fbc8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0920bf76-c8a0-434e-a0fe-736ed8b54b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 24 15:15:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.56       Driver Version: 527.56       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   46C    P8    34W / 450W |   7366MiB / 24564MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3144      C   ...conda3\\envs\\cv\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      9112    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     10056    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     10184    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10192    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     10628    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11300    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12800    C+G   ...gram Desktop\\Telegram.exe    N/A      |\n",
      "|    0   N/A  N/A     14156    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14340    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     14712    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14968    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     17544      C   ...conda3\\envs\\cv\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     18100    C+G   ...r\\Application\\browser.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f07e8ce7-6649-489e-b098-ff39c1cdc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "for file in glob('rgb_yolo/train/*txt'):\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        annot = f.read().split('\\n')\n",
    "\n",
    "    new_annot = []\n",
    "    \n",
    "    for annot_ in annot:\n",
    "        if len(annot_.split()[1:]) >= 6:\n",
    "            annot_ = '0 ' + annot_[2:]\n",
    "            new_annot.append(annot_)\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        f.write('\\n'.join(new_annot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b892775b-1916-40b4-9f50-a0d40f66172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "for file in glob('rgb_yolo/val/*txt'):\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        annot = f.read().split('\\n')\n",
    "\n",
    "    new_annot = []\n",
    "    \n",
    "    for annot_ in annot:\n",
    "        if len(annot_.split()[1:]) >= 6:\n",
    "            annot_ = '0 ' + annot_[2:]\n",
    "            new_annot.append(annot_)\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        f.write('\\n'.join(new_annot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5662cca2-f882-4f8e-9478-11d69b1c1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3479a4d1-7363-430f-a8db-f935a95552cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.216 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208  Python-3.10.13 torch-2.2.0.dev20231110+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24564MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=runs/best.pt, data=rgb_yolo/data.yml, epochs=100, patience=50, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\train3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1  12327764  ultralytics.nn.modules.head.Segment          [12, 32, 320, [320, 640, 640]]\n",
      "YOLOv8x-seg summary: 401 layers, 71762404 parameters, 71762388 gradients, 344.6 GFLOPs\n",
      "\n",
      "Transferred 657/657 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\code\\UBC\\rgb_yolo\\train.cache... 4550 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4550/4550 [\u001b[0m\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\code\\UBC\\rgb_yolo\\val.cache... 506 images, 1 backgrounds, 0 corrupt: 100%|██████████| 506/506 [00:00<?\u001b[0m\n",
      "Plotting labels to runs\\segment\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 106 weight(decay=0.0), 117 weight(decay=0.0005), 116 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\train3\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100      14.7G      2.161      3.473      2.216      1.432        742        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537       0.28      0.238      0.155      0.094      0.274      0.228      0.146      0.076\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      16.7G      1.554      2.622      1.553      1.148        317        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.273      0.312      0.233      0.153      0.271      0.303      0.225      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      15.8G      1.447      2.428      1.417        1.1        193        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.365      0.327      0.287      0.194      0.359       0.32      0.278      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      16.4G      1.378      2.307      1.333      1.079        320        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.455      0.381      0.358       0.25      0.443      0.374      0.349      0.214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      16.6G      1.329      2.219      1.251      1.057        249        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.477      0.374      0.372      0.265      0.474      0.367      0.365      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      15.2G      1.289      2.144       1.19      1.043        354        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537       0.48      0.425      0.409      0.293      0.473      0.417      0.401      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      15.1G       1.26      2.096       1.15      1.034        342        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537       0.52      0.444      0.441      0.322      0.515      0.437      0.434      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      17.8G      1.235      2.047      1.105      1.022        661        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.587      0.425      0.462      0.338      0.597      0.414      0.453      0.285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      14.7G        1.2      1.988      1.063      1.009        319        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.586      0.465      0.492      0.361       0.59      0.458      0.483      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      17.6G      1.189      1.962      1.038      1.002        156        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.556      0.475      0.502      0.371      0.573      0.455      0.495      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      16.6G      1.169      1.917      1.006     0.9952        260        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.581      0.511      0.514       0.38      0.585      0.503      0.507      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100        16G       1.15      1.885     0.9728     0.9874        674        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.576      0.498      0.529      0.394      0.575      0.494      0.524      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      18.8G      1.142      1.866      0.957     0.9823        458        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.637        0.5      0.553      0.415      0.635      0.496      0.547      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      14.4G      1.114       1.82     0.9289     0.9773        366        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.657      0.507      0.565      0.424      0.651      0.502      0.554      0.361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      16.1G      1.115      1.828     0.9208      0.977        198        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.646       0.55      0.597      0.448      0.643      0.544       0.59      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      16.7G      1.092      1.775     0.8963     0.9698        490        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.636      0.554      0.596      0.455      0.632      0.549      0.589       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      16.8G      1.084      1.763     0.8735     0.9664        449        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.696      0.567      0.628      0.476      0.694      0.563      0.622      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      15.7G      1.066      1.731     0.8491     0.9567        408        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.692       0.57       0.62      0.477      0.694      0.569      0.616      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100        15G      1.057      1.713     0.8388     0.9565        204        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.734      0.577       0.64       0.49      0.744      0.566      0.632       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      15.4G      1.037      1.675     0.8181     0.9489        271        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.725      0.581      0.656      0.505       0.73      0.574      0.649      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      18.5G      1.045       1.69     0.8092     0.9484        480        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.741      0.599       0.67       0.52      0.758      0.584      0.661      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      19.5G      1.028      1.659      0.802     0.9449        733        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.768      0.575      0.672      0.524      0.748      0.588      0.666       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      14.9G      1.014      1.636     0.7741     0.9403        424        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.774      0.617      0.693       0.54      0.784      0.605      0.685      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      15.2G      1.011      1.634     0.7666      0.938        334        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.758      0.616      0.689      0.532      0.756      0.613      0.681      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      16.9G     0.9966      1.609     0.7586     0.9344        362        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.773      0.611      0.699      0.546      0.787      0.598      0.688      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      15.6G     0.9818      1.579     0.7388     0.9305        278        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.762       0.64      0.698      0.548      0.759      0.633      0.688      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      17.9G     0.9838      1.585      0.733     0.9275        330        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.781      0.638      0.711      0.559       0.78      0.633      0.703      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      15.1G     0.9711      1.557     0.7224      0.927        553        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.771      0.649      0.723      0.565      0.788      0.633      0.715       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      17.5G     0.9661      1.552     0.7163     0.9248        232        512: 100%|██████████| 285/285 [02:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP\n",
      "                   all        506      29537      0.793      0.656      0.734      0.579       0.79      0.649      0.724      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      14.8G       0.96      1.541     0.7044     0.9199       1212        512:  91%|█████████ | 260/285 [01:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# model = YOLO('runs/segment/train15/weights/best.pt')  # load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Use the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_yolo/data.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# , lr0=1e-6 \u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# single_cls=True, \u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# conf=0.5, iou=0.5\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# train the model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\cv\\lib\\site-packages\\ultralytics\\engine\\model.py:338\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\cv\\lib\\site-packages\\ultralytics\\engine\\trainer.py:190\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\cv\\lib\\site-packages\\ultralytics\\engine\\trainer.py:356\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    354\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;28;01mif\u001b[39;00m loss_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 356\u001b[0m     \u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_description\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%11s\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%11.4g\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_batch_end\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;129;01mand\u001b[39;00m ni \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_idx:\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\cv\\lib\\site-packages\\tqdm\\std.py:1383\u001b[0m, in \u001b[0;36mtqdm.set_description\u001b[1;34m(self, desc, refresh)\u001b[0m\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_miniters \u001b[38;5;241m=\u001b[39m EMA(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmoothing)\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m-> 1383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_description\u001b[39m(\u001b[38;5;28mself\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;124;03m    Set/modify description of the progress bar.\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m        Forces refresh [default: True].\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesc \u001b[38;5;241m=\u001b[39m desc \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m desc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/best.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO('runs/segment/train15/weights/best.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "model.train(data=\"rgb_yolo/data.yml\", imgsz=512, batch=16, epochs=100\n",
    "            # , lr0=1e-6 \n",
    "            # single_cls=True, \n",
    "            # conf=0.5, iou=0.5\n",
    "           )  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eacba2-0b84-4a8d-9c69-669fa2986466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6614f30-0139-4d10-a59d-9af8566de4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5b82f4c-581d-403b-8ea1-ddf82af8c775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\code\\UBC\\sar_yolo\\val\\GF2_Barcelona_41.4186_2.1956.png: 512x512 107 flat_roofs, 1 gable_roof, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 56.1ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Run inference on 'bus.jpg'\n",
    "model = YOLO('runs/segment/train15/weights/best.pt')\n",
    "results = model.predict('sar_yolo/val/GF2_Barcelona_41.4186_2.1956.png', max_det=1000, conf=0.1, iou=0.5)  # results list\n",
    "\n",
    "# Show the results\n",
    "for r in results:\n",
    "    im_array = r.plot(line_width=1, font_size=1, boxes=False)  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    # im.show()  # show image\n",
    "    im.save('results_sar.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22403500-8d1f-4cfe-9e5c-ef6ab692c15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
